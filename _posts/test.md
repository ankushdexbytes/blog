
# Spark Structured Streaming Checkpointing

In Structured Streaming, if you enable checkpointing for a streaming query, then you can restart the query after a failure and the restarted query will continue where the failed one left off, while ensuring fault tolerance and data consistency guarantees.

## Why needed?
The primary goal of checkpointing is to ensure the fault-tolerance of streaming jobs. Thanks to the metadata stored in checkpoint files you will be able to restart your processing in case of any failure - business logic or technical error.

Checkpoints are also important to guarantee at-least once processing in case of any failure in the middle of currently processed micro-batch.

## Enable checkpointing
To enable checkpointing, set the option `checkpointLocation` to a HDFS or cloud storage path. For example:
```scala
streamDataFrame.writeStream
  .format("csv")
  .option("path", "/outputStoragePath")
  .option("checkpointLocation", "/checkpointPath")
  .start()
```
## What is stored in Checkpoint Path
Checkpoint is a physical directory and responsible for storing 4 types of directories:

-   source - files in this directory contain the information about different sources used in the streaming query. For example, for Apache Kafka the checkpointed source file will contain a map between topic partitions and offsets at the first query execution. This value is immutable and doesn't change between query executions.
-   offsets - contains a file with information about data that will be processed in given micro-batch execution. It's generated before the physical execution of the micro-batch. Internally it's represented by  _org.apache.spark.sql.execution.streaming.OffsetSeqLog_  class.
-   commit logs - it's a kind of marker file with the information about the watermark used in the next micro-batch. Internally it's represented by  _org.apache.spark.sql.execution.streaming.CommitLog_  class and the metadata is represented as  _org.apache.spark.sql.execution.streaming.CommitMetadata_.
-   state - it'll be the topic of another post but checkpoint location is also responsible for the storage of state generated by stateful processing logic.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4NDc2OTYzNzcsLTE2OTMxMzgzNTEsMT
Y1NjEzMjYyOCwyNDE3Mzg0NzcsNjg0MjA1MzcwLDE2MDA0MDM0
MzEsLTcyNzAxNTAwNywtOTU5MTM5Mjc4LDk4NTYzNTY1NCwtMT
U0MjYwODI1NCwtMTk0MjI4MzIyMCwtNDIyMzE4OTk0LC0zMjQy
ODA3MzAsLTIxMTQ1MDA0ODMsLTIxMjI0NjU3ODEsNDU4ODkwMD
EzLC0xNjU2ODc3MDEwLDExODM0NTIzNDgsLTE4OTU5ODk1NTEs
MjExNzgxMjg4MV19
-->