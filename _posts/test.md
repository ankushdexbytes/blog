
# Probabilistic Data structures in Analysis of Big Data
Big data is a collection of large amount of data which increases in volume, velocity and variety. In this blog discuses the methods of using Probabilistic Data Structure in Big Data Analysis and primarily focused on **Bloom Filter** which decreased the space or time.

The conventional data structures and algorithm are not sufficient to manage larger and more complex dataset of Big Data.

## What is PROBABILISTIC DATA STRUCTURE
Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. 

The main-stream data structures like Lists, Maps, Sets, Trees etc. are mostly used for achieving certain results about whether the data exist or not, maybe along with their number of occurrences and such.

But these Data Structures are not suitable for analysis of the huge capacity of Big Data because the computational and time complexity is large. Probabilistic Data Structure is more efficient in its involvement of constant factor in actual run time. Thus they are suitable for Big Data processing.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTc0Nzk3MjY0MCwtMjEyMjQ2NTc4MSw0NT
g4OTAwMTMsLTE2NTY4NzcwMTAsMTE4MzQ1MjM0OCwtMTg5NTk4
OTU1MSwyMTE3ODEyODgxLDE1MDUyNzAyOTYsLTE5Njg2NzE3My
wtNjM3MzM2MDA2LC04MjI4MTgyNDAsLTIwNzMzNTQ2NzgsMTI1
NzkxMzc2OCwtNzM0MjYzMTkzLDE3MTcyMTk3NzQsLTkzOTczNj
E1OCwtMTAwOTY0NTAxMywtNzkyMDk4OTAyLC0xNjE2NjI4ODE2
LC0xMDI4MDYyOTI1XX0=
-->