
# Spark Structured Streaming Checkpointing

In Structured Streaming, if you enable checkpointing for a streaming query, then you can restart the query after a failure and the restarted query will continue where the failed one left off, while ensuring fault tolerance and data consistency guarantees.

## Why needed?
The primary goal of checkpointing is to ensure the fault-tolerance of streaming jobs. Thanks to the metadata stored in checkpoint files you will be able to restart your processing in case of any failure - business logic or technical error.

Checkpoints are also important to guarantee at-least once processing in case of any failure in the middle of currently processed micro-batch.

## Enable checkpointing
To enable checkpointing, set the option `checkpointLocation` to a HDFS or cloud storage path. For example:
```scala
streamDataFrame.writeStream
  .format("csv")
  .option("path", "/outputStoragePath")
  .option("checkpointLocation", "/checkpointPath")
  .start()
```
## What is stored in Checkpoint Path
Checkpoint is a physical directory and responsible for storing 4 types of directories:

-   **source :** files in this directory contain the information about different sources used in the streaming query.
-   **offsets :** The Offset directory contains a file with information about data that will be processed in given micro-batch execution. It's generated before the physical execution of the micro-batch.
-   **commits :** The Commits directory is a marker kind of file and generated for each micro-batch. 
-   **state :** it'll be responsible for the storage of state generated by stateful processing logic.

## How checkpoint enforces exactly once delivery guarantee
Let's see how checkpoint works in File Sink.
```scala
streamDataFrame.writeStream
  .format("csv")
  .option("path", "/outputStoragePath")
  .option("checkpointLocation", "/checkpointPath")
  .start()
```
In the above example we have provided **Checkpoint directory** and **Storage directory** Paths.

 - **Under the Checkpoint directory :** we have an offsets directory and that commits directory.
 - **Under the Storage directory :** we have an actual data files and 

<!--stackedit_data:
eyJoaXN0b3J5IjpbNjQ4MzA0NjY3LC0xNTIyMzQxMjg3LC00Nz
Q0NjcxMjEsODU4NjIwNDY0LDc4NzEyNzI1MSwtMTg0NzY5NjM3
NywtMTY5MzEzODM1MSwxNjU2MTMyNjI4LDI0MTczODQ3Nyw2OD
QyMDUzNzAsMTYwMDQwMzQzMSwtNzI3MDE1MDA3LC05NTkxMzky
NzgsOTg1NjM1NjU0LC0xNTQyNjA4MjU0LC0xOTQyMjgzMjIwLC
00MjIzMTg5OTQsLTMyNDI4MDczMCwtMjExNDUwMDQ4MywtMjEy
MjQ2NTc4MV19
-->