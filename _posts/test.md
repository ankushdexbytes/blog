
# Probabilistic Data structures in Analysis of Big Data
Big data is a collection of large amount of data which increases in volume, velocity and variety. In this blog discuses the methods of using Probabilistic Data Structure in Big Data Analysis and primarily focused on **Bloom Filter** which decreased the space or time.

The conventional data structures and algorithm are not sufficient to manage larger and more complex dataset of Big Data.

## What is PROBABILISTIC DATA STRUCTURE
Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. 

The main-stream data structures like Lists, Maps, Sets, Trees etc. are mostly used for achieving certain results about whether the data exist or not, maybe along with their number of occurrences and such.

But these Data Structures are not suitable for analysis of the huge capacity of Big Data because the computational and time complexity is large. Probabilistic Data Structure is more efficient of constant run time.

These techniques are based on hash functions to represent a set of elements randomly. They provide answer approximately. However, reliable sources to estimate error is also given. They use much less memory and have constant query time. They can be paralleled and supports union and intersection operations. All these make Probabilistic Data Structure suitable for
Big Data Analysis and Processing. They are used in all the aspects of Big Data, viz., Volume to check the membership, Velocity to find frequency and rank and Variety to check similarity.

<!--stackedit_data:
eyJoaXN0b3J5IjpbMjA4MDA0NTkwNCwtMjEyMjQ2NTc4MSw0NT
g4OTAwMTMsLTE2NTY4NzcwMTAsMTE4MzQ1MjM0OCwtMTg5NTk4
OTU1MSwyMTE3ODEyODgxLDE1MDUyNzAyOTYsLTE5Njg2NzE3My
wtNjM3MzM2MDA2LC04MjI4MTgyNDAsLTIwNzMzNTQ2NzgsMTI1
NzkxMzc2OCwtNzM0MjYzMTkzLDE3MTcyMTk3NzQsLTkzOTczNj
E1OCwtMTAwOTY0NTAxMywtNzkyMDk4OTAyLC0xNjE2NjI4ODE2
LC0xMDI4MDYyOTI1XX0=
-->