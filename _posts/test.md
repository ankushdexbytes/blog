
# Probabilistic Data structures in Analysis of Big Data
Big data is a collection of large amount of data which increases in volume, velocity and variety. In this blog discuses the methods of using Probabilistic Data Structure in Big Data Analysis and primarily focused on **Bloom Filter** which decreased the space or time.

The conventional data structures and algorithm are not sufficient to manage larger and more complex dataset of Big Data.

## What is PROBABILISTIC DATA STRUCTURE
Data structures are nothing different. They are like the bookshelves of your application where you can organize your data. Different data structures will give you different facility and benefits. 

The main-stream data structures like Lists, Maps, Sets, Trees etc. are mostly used for achieving certain results about whether the data exist or not, maybe along with their number of occurrences and such.

But these Data Structures are not suitable for analysis of the huge capacity of Big Data because the computational and time complexity is large. Probabilistic Data Structure is more efficient of constant run time.

**PROBABILISTIC DATA STRUCTURE**  are based on hash functions to represent a set of elements randomly. They provide answer approximately. They use much less memory and constant query time. They can be paralleled and supports union and intersection operations. All these make Probabilistic Data Structure suitable for
Big Data Analysis and Processing. They are used in all the aspects of Big Data, viz., Volume to check the membership, Velocity to find frequency and rank and Variety to check similarity.

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIxMTQ1MDA0ODMsLTIxMjI0NjU3ODEsND
U4ODkwMDEzLC0xNjU2ODc3MDEwLDExODM0NTIzNDgsLTE4OTU5
ODk1NTEsMjExNzgxMjg4MSwxNTA1MjcwMjk2LC0xOTY4NjcxNz
MsLTYzNzMzNjAwNiwtODIyODE4MjQwLC0yMDczMzU0Njc4LDEy
NTc5MTM3NjgsLTczNDI2MzE5MywxNzE3MjE5Nzc0LC05Mzk3Mz
YxNTgsLTEwMDk2NDUwMTMsLTc5MjA5ODkwMiwtMTYxNjYyODgx
NiwtMTAyODA2MjkyNV19
-->